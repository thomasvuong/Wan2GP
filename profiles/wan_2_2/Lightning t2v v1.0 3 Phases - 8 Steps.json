{
    "num_inference_steps": 8,
    "guidance_scale": 3.5,
    "guidance2_scale": 1,
    "guidance3_scale": 1,
    "switch_threshold": 965,
    "switch_threshold2": 800,
    "guidance_phases": 3,
    "model_switch_phase": 2,
    "flow_shift": 3,
    "sample_solver": "euler",	
	"activated_loras": [
		"https://huggingface.co/DeepBeepMeep/Wan2.2/resolve/main/loras_accelerators/Wan2.2-Lightning_T2V-v1.1-A14B-4steps-lora_HIGH_fp16.safetensors",
		"https://huggingface.co/DeepBeepMeep/Wan2.2/resolve/main/loras_accelerators/Wan2.2-Lightning_T2V-v1.1-A14B-4steps-lora_LOW_fp16.safetensors"
	],
	"loras_multipliers": "0;1;0 0;0;1",
	"help": "This finetune uses the Lightning 4 steps Loras Accelerator for Wan 2.2 but extend them to 8 steps in order to insert a CFG phase before the 2 accelerated phases with no Guidance. The ultimate goal is reduce the slow motion effect of these Loras Accelerators."
}